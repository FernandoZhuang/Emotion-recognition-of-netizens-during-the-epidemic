{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import my_setting.utils as utils\n",
    "import cufflinks as cf\n",
    "import jieba\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "%matplotlib inline\n",
    "cf.go_offline()\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('max_colwidth',100)\n",
    "plt.style.use('seaborn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4456074364642450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4456069114155340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4456068145061890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4456064403586410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4456060284446840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4456059202748560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4456055234844520</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4456071538097160</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4456071366149900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4456070334552490</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  y\n",
       "0  4456074364642450  0\n",
       "1  4456069114155340  0\n",
       "2  4456068145061890  0\n",
       "3  4456064403586410  0\n",
       "4  4456060284446840  0\n",
       "5  4456059202748560  0\n",
       "6  4456055234844520  0\n",
       "7  4456071538097160  0\n",
       "8  4456071366149900  0\n",
       "9  4456070334552490  0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_900k=pd.read_csv('/home/zhw/PycharmProjects/nCovSentimentAnalysis/Output/submit_file.csv',encoding='utf-8')\n",
    "output_900k.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": true
       },
       "data": [
        {
         "labels": [
          0,
          -1
         ],
         "marker": {
          "colors": [
           "rgba(255, 153, 51, 1.0)",
           "rgba(55, 128, 191, 1.0)"
          ]
         },
         "name": "",
         "type": "pie",
         "values": [
          882102,
          17898
         ]
        }
       ],
       "layout": {
        "legend": {
         "bgcolor": "#F5F6F9",
         "font": {
          "color": "#4D5663"
         }
        },
        "paper_bgcolor": "#F5F6F9",
        "plot_bgcolor": "#F5F6F9",
        "title": "Labels",
        "titlefont": {
         "color": "#4D5663"
        }
       }
      },
      "text/html": [
       "<div>\n",
       "        \n",
       "        \n",
       "            <div id=\"2f5cc078-1f28-4ba5-b46c-2974c1eb463e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                require([\"plotly\"], function(Plotly) {\n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    window.PLOTLYENV.BASE_URL='https://plot.ly';\n",
       "                    \n",
       "                if (document.getElementById(\"2f5cc078-1f28-4ba5-b46c-2974c1eb463e\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        '2f5cc078-1f28-4ba5-b46c-2974c1eb463e',\n",
       "                        [{\"labels\": [0, -1], \"marker\": {\"colors\": [\"rgba(255, 153, 51, 1.0)\", \"rgba(55, 128, 191, 1.0)\"]}, \"name\": \"\", \"type\": \"pie\", \"values\": [882102, 17898]}],\n",
       "                        {\"legend\": {\"bgcolor\": \"#F5F6F9\", \"font\": {\"color\": \"#4D5663\"}}, \"paper_bgcolor\": \"#F5F6F9\", \"plot_bgcolor\": \"#F5F6F9\", \"title\": \"Labels\", \"titlefont\": {\"color\": \"#4D5663\"}},\n",
       "                        {\"showLink\": true, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\", \"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('2f5cc078-1f28-4ba5-b46c-2974c1eb463e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                });\n",
       "            </script>\n",
       "        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp=output_900k['y'].value_counts()\n",
    "temp_df=pd.DataFrame({'labels':temp.index,'values':temp.values})\n",
    "temp_df.iplot(kind='pie',labels='labels',values='values',title='Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplify_weibo=pd.read_csv('/home/zhw/PycharmProjects/nCovSentimentAnalysis/Data/UTF8nCoV_900k_train.unlabled.csv',encoding='utf-8')\n",
    "simplify_weibo.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplify_weibo.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(simplify_weibo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=simplify_weibo['label'].value_counts()\n",
    "temp_df=pd.DataFrame({'labels':temp.index,'values':temp.values})\n",
    "temp_df.iplot(kind='pie',labels='labels',values='values',title='Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplify_weibo['length']=simplify_weibo['review'].astype(str).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax1=plt.subplots(1,figsize=(14,8))\n",
    "sns.distplot(simplify_weibo['length'],ax=ax1,color='green')\n",
    "plt.rcParams['font.family']='STSong'\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "ax1.set_title('长度分布')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nip_corpus=pd.read_csv('/home/zhw/PycharmProjects/nCovSentimentAnalysis/Data/SentimentRelevantCorpus/unzip/chineseNIP_weibo_senti_100k.csv',encoding='utf-8')\n",
    "nip_corpus.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nip_corpus.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "msno.bar(nip_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "temp = nip_corpus['label'].value_counts()\n",
    "temp_df = pd.DataFrame({'labels':temp.index,'values':temp.values})\n",
    "temp_df.iplot(kind='pie',labels='labels',values='values',title='Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nip_corpus['length']=nip_corpus['review'].astype(str).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(1,figsize=(14,8))\n",
    "sns.distplot(nip_corpus['length'],ax=ax1, color='green')\n",
    "plt.rcParams['font.family']='SIMHEI' \n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "ax1.set_title('训练集微博长度分布')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据\n",
    "\n",
    "由于其他编码会出现少部分汉字乱码，比如“XX超话”、表情符号等。所以我手动用记事本转换成了 UTF-8 编码。\n",
    "\n",
    "其中，超话以及其他特殊字符以“”表示，大部分表情符号被“??”代替。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "train_labeled = pd.read_csv('/home/zhw/PycharmProjects/nCovSentimentAnalysis/Data/UTF8nCoV_100k_train.labled.csv', encoding='utf-8')\n",
    "train_labeled.rename(columns = {\"微博id\": \"Weibo_ID\",\n",
    "                                \"微博发布时间\": \"Publish_Time\", \n",
    "                                \"发布人账号\": \"Account_ID\",\n",
    "                                \"微博中文内容\": \"Chinese_Content\",\n",
    "                                \"微博图片\": \"Pictures\",\n",
    "                                \"微博视频\": \"Videos\",\n",
    "                                \"情感倾向\": \"Labels\"},  inplace=True)\n",
    "\n",
    "train_labeled_copy = train_labeled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('/home/zhw/PycharmProjects/nCovSentimentAnalysis/Data/UTF8nCov_10k_test.csv', encoding='utf-8')\n",
    "test.rename(columns = {\"微博id\": \"Weibo_ID\",\n",
    "                                \"微博发布时间\": \"Publish_Time\", \n",
    "                                \"发布人账号\": \"Account_ID\",\n",
    "                                \"微博中文内容\": \"Chinese_Content\",\n",
    "                                \"微博图片\": \"Pictures\",\n",
    "                                \"微博视频\": \"Videos\"},  inplace=True)\n",
    "\n",
    "test_copy = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 缺失值检查\n",
    "\n",
    "检查一下训练集和测试集的缺失值，可以看出有些数据是缺失的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(train_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有少量微博正文数据丢失，部分labels为空。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标签检查\n",
    "\n",
    "标签统计如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled_copy.fillna({\"Labels\": \"empty_label\"}, inplace=True)\n",
    "\n",
    "temp = train_labeled_copy[\"Labels\"].value_counts()\n",
    "temp_df = pd.DataFrame({'labels': temp.index,\n",
    "                        'values': temp.values})\n",
    "\n",
    "temp_df.iplot(kind='pie',labels='labels',values='values', title='Labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有6种噪音标签，每种各一个，此外还有一点点空标签，统计如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = train_labeled_copy[(train_labeled_copy[\"Labels\"] != '0') & \n",
    "                           (train_labeled_copy[\"Labels\"] != '1') & \n",
    "                           (train_labeled_copy[\"Labels\"] != '-1')]\n",
    "\n",
    "noise = noise[\"Labels\"].value_counts()\n",
    "noise_df = pd.DataFrame({'labels': noise.index,\n",
    "                         'values': noise.values})\n",
    "\n",
    "noise_df.iplot(kind='pie',labels='labels',values='values', title='奇怪标签统计')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于非正常标签的处理，可以直接舍弃，也可以手工打上真正标签（如果不嫌累）。\n",
    "\n",
    "这里我们直接舍弃就行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled_copy['time'] = pd.to_datetime('2020年' + train_labeled['Publish_Time'], format='%Y年%m月%d日 %H:%M', errors='ignore')\n",
    "test_copy['time'] = pd.to_datetime('2020年' + train_labeled['Publish_Time'], format='%Y年%m月%d日 %H:%M', errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled_copy['month'] =  train_labeled_copy['time'].dt.month\n",
    "train_labeled_copy['day'] =  train_labeled_copy['time'].dt.day\n",
    "train_labeled_copy['dayfromzero']  = (train_labeled_copy['month'] - 1) * 31 +  train_labeled_copy['day']\n",
    "\n",
    "test_copy['month'] =  test_copy['time'].dt.month\n",
    "test_copy['day'] =  test_copy['time'].dt.day\n",
    "test_copy['dayfromzero']  = (test_copy['month'] - 1) * 31 +  test_copy['day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "sns.kdeplot(train_labeled_copy.loc[train_labeled_copy['Labels'] == '0', 'dayfromzero'], ax=ax[0], label='sent(0)')\n",
    "sns.kdeplot(train_labeled_copy.loc[train_labeled_copy['Labels'] == '1', 'dayfromzero'], ax=ax[0], label='sent(1)')\n",
    "sns.kdeplot(train_labeled_copy.loc[train_labeled_copy['Labels'] == '-1', 'dayfromzero'], ax=ax[0], label='sent(-1)')\n",
    "\n",
    "train_labeled_copy.loc[train_labeled_copy['Labels'] == '0', 'dayfromzero'].hist(ax=ax[1])\n",
    "train_labeled_copy.loc[train_labeled_copy['Labels'] == '1', 'dayfromzero'].hist(ax=ax[1])\n",
    "train_labeled_copy.loc[train_labeled_copy['Labels'] == '-1', 'dayfromzero'].hist(ax=ax[1])\n",
    "ax[1].legend(['sent(0)', 'sent(1)','sent(-1)'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出如下情况，顺便也帮大家找了找相关新闻节点（深藏功与名）：\n",
    "\n",
    "- **1月18日**后，话题量有明显增长。\n",
    "    - 1月19日：武汉CDC李刚：新冠人传人风险较低，传染力不强。\n",
    "    - 1月20日：钟南山:新型肺炎存在人传人现象。\n",
    "    - 1月20日：口罩出现抢购现象。\n",
    "    - 1月23日：武汉封城。\n",
    "    - 1月25日：火神山医院设计方案完成；雷神山医院建造决定。\n",
    "\n",
    "- **二月九日**前后，话题量达到顶峰。\n",
    "    - 2月7日：“吹哨人”李文亮医生不幸去世。\n",
    "    - 2月10日：湖北省相关领导任免。\n",
    "\n",
    "18日前官方口径（包括网友）们的态度还比较乐观，大部分认为“新冠可防可控”、“传染力有限”，然后钟南山院士对新冠“肯定存在人传人”的表态可能是导致话题量飙升的重要原因。\n",
    "\n",
    "7日晚上李文亮医生不幸去世，微博和朋友圈都在刷屏，从曲线上看，相关话题量几乎到达顶峰。\n",
    "\n",
    "（**悼念李文亮医生**）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正文长度统计\n",
    "\n",
    "现在开始统计相关微博的长度，训练集和测试集都有。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled_copy['Chinese_Content_Length'] = train_labeled['Chinese_Content'].astype(str).apply(len)\n",
    "test_copy['Chinese_Content_Length'] = train_labeled['Chinese_Content'].astype(str).apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1,2,figsize=(14,8))\n",
    "sns.distplot(train_labeled_copy['Chinese_Content_Length'], ax=ax1, color='blue')\n",
    "sns.distplot(test_copy['Chinese_Content_Length'], ax=ax2, color='green')\n",
    "\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "ax1.set_title('训练集微博长度分布')\n",
    "ax2.set_title('测试集微博长度分布')\n",
    "\n",
    "plt.show()\n",
    "### 正文词云\n",
    "\n",
    "采用 `jieba` 和 `wordcloud` 对正文做一个词云。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = open('/home/zhw/PycharmProjects/nCovSentimentAnalysis/Docs/cn_stopwords.txt', 'r+', encoding='utf-8')\n",
    "stopword = stop.read().split(\"\\n\")\n",
    "stopeword = set(stopword)\n",
    "stop.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripword(seg):\n",
    "    \"\"\"停用词处理\"\"\"\n",
    "    wordlist = []\n",
    "    \n",
    "    for key in seg.split(' '):\n",
    "        #去除停用词和单字\n",
    "        if not (key.strip() in stopword) and (len(key.strip()) > 1):\n",
    "            wordlist.append(key)\n",
    "    return ' '.join(wordlist)\n",
    "\n",
    "def cutword(content):\n",
    "    \"\"\"分词，去除停用词，写得比较简陋\"\"\"\n",
    "    seg_list = jieba.cut(content)\n",
    "    line = \" \".join(seg_list)\n",
    "    word = stripword(line)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled_copy['Chinese_Content_cut'] = train_labeled['Chinese_Content'].astype(str).apply(cutword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_labeled_copy.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = r'/home/zhw/PycharmProjects/nCovSentimentAnalysis/Docs/MYSH.TTC'\n",
    "wc = WordCloud(font_path=font,\n",
    "               max_words=2000,\n",
    "               width=1800, \n",
    "               height=1600, \n",
    "               mode='RGBA', \n",
    "               background_color=None).generate(str(train_labeled_copy['Chinese_Content_cut'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 12))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 图片统计\n",
    "在训练数据（微博）中，有些是有图片的，有些是没有图片的。\n",
    "\n",
    "我们做一个简单统计："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled_copy['Pic_Length'] = train_labeled_copy['Pictures'].apply(lambda x: len(eval(x)))\n",
    "test_copy['Pic_Length'] = test_copy['Pictures'].apply(lambda x: len(eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 8))\n",
    "ax1.set_xlim(0, 9)\n",
    "ax2.set_xlim(0, 9)\n",
    "\n",
    "sns.distplot(train_labeled_copy['Pic_Length'], bins=25, ax=ax1, color='blue', kde=False)\n",
    "sns.distplot(test_copy['Pic_Length'], bins=25, ax=ax2, color='green', kde=False)\n",
    "\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "ax1.set_title('训练集图片数量分布')\n",
    "ax2.set_title('测试集图片数量分布')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出分布非常近似，这里基本没什么问题。\n",
    "\n",
    "大多数人都是不发图片或者发一张图片。\n",
    "\n",
    "至于9图比7、8图的多，6图比5图多，大概是强迫症..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 视频统计\n",
    "\n",
    "视频计数在训练集和测试集中分布："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labeled_copy['With_Video'] = train_labeled_copy['Videos'].apply(lambda x: len(eval(x)))\n",
    "test_copy['With_Video'] = test_copy['Videos'].apply(lambda x: len(eval(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 8))\n",
    "\n",
    "sns.countplot(train_labeled_copy['With_Video'], ax=ax1, color='grey')\n",
    "sns.countplot(test_copy['With_Video'], ax=ax2, color='orange')\n",
    "\n",
    "plt.rcParams['font.sans-serif']=['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "ax1.set_title('训练集视频分布')\n",
    "ax2.set_title('测试集视频分布')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看起来分布是一致的。\n",
    "\n",
    "接下来我们看看带视频和不带视频的情感标签分布。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_labeled_copy_2 = train_labeled_copy[(train_labeled_copy[\"Labels\"] == '0') |\n",
    "                                          (train_labeled_copy[\"Labels\"] == '1') |\n",
    "                                          (train_labeled_copy[\"Labels\"] == '-1')]\n",
    "\n",
    "sns.countplot(x='With_Video', hue='Labels', data= train_labeled_copy_2,\n",
    "              order = train_labeled_copy['With_Video'].dropna().value_counts().index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "可以看出，大部分带视频的微博，其情感为中性。\n",
    "\n",
    "但是明显的，相对于不带视频的微博，带视频的微博中 `正面情感` 比例比 `负面情感` 的比例更高。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
